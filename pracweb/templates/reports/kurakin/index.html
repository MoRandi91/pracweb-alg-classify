{% extends "reports_base.html" %}
{% block author %}Александр Куракин{% endblock %}
{% block topic %}Настройка суперпозиции корректирующих операторов{% endblock %}

{% block report %}
	<div id='toc'></div>

	<h1>Введение</h1>
	
	<p>Одна из наиболее распространенных задач машинного обучения &mdash; задача классификации.
	Она состоит в распределении объектов по классам в результате обучения по прецедентам.
	В данной работе мы рассмотрим алгебраический подход к задаче классификации.
	Идея этого подхода простая и красивая. Трудно построить сразу нужный алгоритм, 
	действующий из пространства начальных информаций в пространство финальных информаций.
	Поэтому мы делаем это в два шага: сначала переходим в удобное нам вспомогательное пространство оценок,
	а из него уже в итоговое пространство.</p>

	<p>Также в этом подходе возникает возможность рассматривать различные суперпозиции 
	алгоритмических операторов. Это расширяет семейство алгоритмов и может привести к повышению качества
	получаемого решения.</p>

	<p>В данном задании мы применяем этот подход на практике,
	рассматриваем несколько моделей операторов и корректирующих семейств,
	их суперпозиции, делаем выводы о качестве работы построенных алгоритмов.</p>
	
	<h1>Задача классификации</h1>

	<h2>Неформальная постановка (общая постановка)</h2>

	<p>На неформальном языке задача классификации заключается в некотором "разумном" отнесении объектов к классам. 
	Будем рассматривать $q$ объектов и $l$ классов. Задача классификации -- задача обучения с учителем.
	Поэтому рассматривается также обучающая выборка: множество $m$ объектов, для которых известны принадлежности к классам.</p>
	
	<h2>Формальная постановка (дано)</h2>

	<p>Опишем общую постановку задачи формально</p>

	<h3>Пространство описаний объектов, дескриптивная функция</h3>
	<p> $I_{ob}$ &mdash; пространство описаний объектов. Дескриптивная функция $D$ сопоставляет каждому объекту
	его признаковое описание. Например, $D(s) = \|\rho_t(s, s^k)\|_{mn}$, где s &mdash; рассмтриваемый объект, 
	$s^k$ &mdash; объект обучающей выборки $k = 1, \dots m$, $\rho_t$ &mdash; некоторая метрика, $t = 1, \dots n$. 
	Tогда $I_{ob} = \mathfrak{C_{mn}}(\mathbb{R}_{+})$.</p>

	<h3>Пространство описаний классов</h3>
	<p>$I_{cl}$&mdash; пространство описаний классов. Например, описанием j-го класса может быть вектор 
	$(P_j(s^1), \dots P_j(s^m))$, где $P_j$ &mdash; предикат, говорящий о принадлежности объектов данному классу.
	Тогда $I_{cl} = E_2^m$.</p>

	<h3>Пространство начальных информаций</h3>
	<p>$\mathfrak{I_i}$ &mdash; пространство начальных информаций. Это пространство матриц размерности $q$ на $l$:
	$\mathfrak{I_i} = \mathfrak{C_{ql}(\mathfrak{I})}$,
	где $\mathfrak{I}$ &mdash; пространство совместных описаний объектов и классов, т.е. $\mathfrak{I} = I_{ob} \times I_{cl}$.</p>

	<h3>Пространство финальных информаций</h3>
	<p>$\mathfrak{I_f}$ &mdash; пространство финальных информаций. Это пространство матриц той же размрности: $\mathfrak{I_i} = \mathfrak{C_{ql}(\mathfrak{\tilde{I}})}$,
	где $\mathfrak{\tilde{I}} = E_2$, т.е. каждый элемент матрицы говорит о принадлежности соответсвующего объекта соответсвующему классу; </p>

	<h3>Универсальные ограничения</h3>
	<p>$I^u$ &mdash; универсальные ограничения. Эти ограничения не проверяются констрактивно, а задаются как некоторый "мешок" отображений,
	например, непрерывные отображения, монотонные, или в общем случае &mdash; отображения некоторой категории.</p>

	<h3>Локальные ограничения</h3>
	<p>$I^l$ &mdash; локальные ограничения. Эти ограничения задаются конструктивно. Например, это требование принимать истинные значения на прецедентах.
	Такое требование называется корректностью алгоритма. Заметим, что в данном задании мы не будем вводить такое требование.</p>

	<h3>Модель алгоритмов</h3>
	<p>$\mathfrak{m}$ &mdash; модель алгоритмов, или семейство алгоритмов, удовлетворяющее определенным локальным и глобальным ограничениям.
	$\mathfrak{m:*}$ &mdash; семейство всех возможных алгоримтов.</p>
	
	<h2>Требуется найти алгоритм...</h2>

	<p>Задача заключается в построении алгоритма (отображения) $A$, действующего из пространства начальных информация в пространство финальных информация
	и удовлетворяющих глобальным и локальным ограничениям:
	\[
	A \in \mathfrak{m}^*: \mathfrak{I_i} \rightarrow \mathfrak{I_f}, \quad	A \in \mathfrak{m}^*[I^u], A \in \mathfrak{m}^*[I^l]
	\]
	</p>

	<h2>Корректность алгоритма как способ использовать прецеденты</h2>
	
	<p>В поставленной задаче мы не требуем условия корректности алгоритма,
	т.к. поиск корректного алгоритма часто является неразрешимой задачей, а также может приводить к переобучению.</p>

	<h2>Конкретизация постановки в условиях практикума</h2>

	<p>Перейдем от общей остановки задачи к непостредственно той, которую будем рассматривать в рамках данного задания.</p>

	<h3>Конкретное пространство описаний объектов</h3>
	<p> Объектами являются точки на плоскости. Пространство описания объектов $I_{ob} = \mathbb{R}^2$.</p>
	
	<h3>Конкретные универсальные ограничения</h3>
	<p> Универсальные ограничения $I^u$: однородность объектов (порядок объектов неважен для алгоритма) и независимость объектов
	(алгоритм осущеcтвляет классификацию каждого отдельного объекта независимо).
	Следующим универсальным ограничением является принадлежность объекта только к одному классу.
	Из этого огранчения следует, что классы не являются независимыми.
	Однако классы являются в нашем случае однородными: алгоритм не различает классы и относится одинаково ко всем.
	Кроме того, мы будем рассматривать алгоритмы, принадлежащие только определенному семейству.
	Далее в отчете мы подробно опишем оба рассматриваемых семейства.</p>
	
	<h3>Конкретное пространство начальных информаций</h3>
	<p> Из независимости объектов следует, что можно рассматривать задачу классификации отдельно для каждого объекта.
	Кроме того, договоримся рассматривать информацию о прецедентах и классах как параметры алгоритма.
	Тогда можно сказать, что пространство начальных информаций $\mathfrak{I_i} = \mathbb{R}^2$.</p>
	
	<h3>Конкретное пространство финальных информаций</h3>
	<p> Из условия о принадлежности только одному классу следует, что можно задать результат классификации объекта
	меткой класса: числом из множества $\{1, \dots l\}$. 
	Так как рассматривается алгоритм для классификации отдельного объекта, получаем пространство финальных информаций 
	$\mathfrak{I_f} = \{1, \dots l\}$.</p>
	

	<h1>Оптимизационный подход &mdash; для алгоритмов</h1>

	<h2>Оптимизационная задача для алгоритма и набора прецедентов $ Q(A, \tilde{S}) $</h2>
	<p>В поставленной задаче мы не требуем условия корректности алгоритма,
	т.к. поиск корректного алгоритма часто является неразрешимой задачей, а также может приводить к переобучению.
	Поэтому необходим иной способ учета обучающей информации и выбора алгоритма из семейства.
	При оптимизационном подходе вводится некоторый функционал качества и выбирается алгоритм, на котором достигается минимум:
	\[
	Q(A, \tilde{S}) \longrightarrow \min,
	\]
	где $\tilde{S}$ &mdash; обучающая выборка.</p>

	<h2>Функционал качества для алгоритма и набора прецедентов $ Q(A, \tilde{S}) $</h2>
	<p>Конкретный вид фукнционала может быть различным. Например, это может быть число ошибок алгоритма на обучающей выборке.
	Тогда мы будем выбирать корректный алгоритм (в случае, если такой алгоритм существует для данной выборки при остальных ограничениях задачи).
	В рамках этого задания мы не будем пользоваться функционалом вида $ Q(A, \tilde{S}) $. 
	В дальнейшем мы рассмотрим алгоритм $ A $ в виде композиции алгоритмического оператора и решающего правила и 
	будем решать оптимизационную задачу для оператора, а не для алгоритма.</p>
	\\subsubsection{
	<h1>Алгебраический подход &mdash; идея декомпозиции</h1>
	
	<h2>Декомпозиция алгоритма на оператор и решающее правило</h2>

	<p>
	В общем случае работать с пространством начальных и финальных информаций неудобно, 
	поэтому в рамках алгебраического подхода решения задач классификации переходят в некоторое пространство, 
	называемое пространство оценок. Его выбирают произвольно, так, чтобы было удобно. 
	Для выполнения этого перехода в другое пространство алгоритм рассматривают как композицию алгоритмического оператора 
	и решающего правила $A = C \circ B$, 
	где $ B: \mathfrak{I_i} \rightarrow \mathfrak{I_e} $ &mdash; алгоритмический оператор, 
	$ C: \mathfrak{I_e} \rightarrow \mathfrak{I_f} $ &mdash; решающее правило. 
	Здесь $\mathfrak{I_e}$ &mdash; пространство оценок. В данном задании выберем $\mathfrak{I_e} = \mathbb{R}^l$.
	</p>
	
	<h2>Картинка с треугольной диаграммой $А=СВ$</h2>
	<img src="diagram0.png"  width="200">
	
	<h2>Конкретизация в условиях практикума</h2>
	<p>
	В рамках данного задания $ B \in \mathfrak{m_0} $, 
	где $ \mathfrak{m_0} = \mathfrak{m_{0_1}} \cup \mathfrak{m_{0_2}} $ &mdash; некоторое семейство операторов &mdash; объединение двух семейств,
	конкретный вид которых будет рассмотрен далее. А решающее правило зафиксируем как $ C = argmax $.
	</p>
	
	<h1>Оптимизационный подход &mdash; для операторов</h1>

	<h2>Идея функционала качества для оператора и набора прецедентов $Q(B,S)$</h2>
	<p>Будем искать не оптимальный алгоритм, а оптимальный оператор, зафиксировав при этом решающее правило, 
	т.е. введем функционал вида $ Q(B, \tilde{S}) $. Этот функционал можно выбирать произвольным образом.</p>
	
	<h2>Оптимизационная постановка задача классификации через $Q(B,S)$</h2>

	<h2>Канонический способ задания $Q(B,S)$</h2>

	<h2>Проблема определения "правильных" оценок, псевдообращение решающего правила</h2>

	<p>Заметим, однако, что при данном подходе мы сталкиваемся с проблемой правильных оценок для элементов обучающей выборки, 
	т.к. мы знаем только метки классов для них, а не оценки.</p>
	
	<h2>Единый для всей работы  функционал $Q(B,S)$ - конкретный в условиях практикума</h2>
	<p>В ходе выполнения данной работы, был выбран функционал качества
	\begin{equation}\label{quality functional for operator}
		Q(B, \tilde{S}) = \frac{1}{q} \sum_{i = 1}^q {\parallel B(S_i) - c_i \parallel^2} \longrightarrow \underset{B}{\min},	
	\end{equation}
	где $ c_i $ &mdash; оценки для объектов: бинарный вектор размерности $l$ с единсвтвенной единицей в позиции,
	соответсвующей классу, которму принадлежит объект.</p>
	
	<h2>Конкретный способ выбора "правильных" оценок в условиях практикума</h2>

	<h2>Сравнение оптимальных и корректных операторов</h2>


	<h1>Алгебраический подход &mdash; идея суперпозиции</h1>

	<h2>Основная идея. Картинка с квадратной диаграммой $А=СFВ$</h2>

	<p>
	Представим теперь наш алгоритм не в виде $ A = C \circ B$, 
	а в виде $ A = C \circ F \circ B $, где $F: \mathfrak{I_e} \rightarrow \mathfrak{I_e}$ &mdash; корректирующая операция.
	</p>
	
	<img src="diagram1.png"  width="220">
	
	<p>
	Основная идея алгебраического подхода состоит в следующем. 
	В общем случае выбранная нами модель операторов может не иметь оптимума, 
	поэтому будем использовать алгебраическое расширение модели. 
	Будем строить не один оператор, а несколько, и использовать их суперпозицию $A = C \circ F(B_1, \dots, B_p)$.
	</p>
	
	<img src="diagram2.png"  width="310">
	
	<h2>Операции над операторами, которые снова дают отображения с сигнатурой операторов</h2>
	<p>
	Корректирующие операции $ F \in \mathfrak{f} $, где $ \mathfrak{f} = \mathfrak{f_1} \cup \mathfrak{f_2} $ &mdash; семейство корректирующих операций, 
	состоящее из двух подсемейств, где $ \mathfrak{f_i} = \{G: \mathfrak{I_e}^p \rightarrow \mathfrak{I_e} | p \in \mathbb{N} \}, i = 1, 2 $.
	</p>
	
	<h2>Операции над оценками индуцируют операции над операторами</h2>

	<p>На самом деле корректирующая операция есть некоторое другое отображение
	\begin{equation}
		F: \{\mathfrak{I_i} \rightarrow \mathfrak{I_e}\}^p \rightarrow \{\mathfrak{I_i} \rightarrow \mathfrak{I_e} \}
	\end{equation}
	Но она индицируется операцией
	\begin{equation}
		G: \mathfrak{I_e}^p \rightarrow \mathfrak{I_e}
	\end{equation}
	если
	\begin{equation}
		F(B_1, \cdots, B_p)(S) = G(B_1(S), \cdots, B_p(S))
	\end{equation}</p>
	
	<h1>Оптимизационный подход &mdash; для суперпозиций</h1>

	<h2>Функционал качества оператора можно применить к результату коррекции</h2>

	<p>Выше мы ввели функционал качества для настройки одного оператора.
	\begin{equation}
		Q: \{\mathfrak{I_i} \rightarrow \mathfrak{I_e} \} \times (\mathfrak{I_i}, \mathfrak{I_e})^q \rightarrow \mathbb{R}
	\end{equation}</p>

	<p>Так как $ F(\cdot) \in \{\mathfrak{I_i} \rightarrow \mathfrak{I_e} \} $, то мы можем в тот же функционал подставить вместо одного оператора суперпозицию.
	\begin{equation}
		Q(F(B_1, \cdots, B_p), \tilde{S}) = \frac{1}{q} \sum_{i = 1}^q {\parallel F(B_1(S_i), \cdots, B_p(S_i)) - c_i \parallel^2}
	\end{equation}</p>

	<h2>Большая оптимизационная задача настройки суперпозиции</h2>
	<p>
	Таким образом, получаем оптимизационную задачу:
	\begin{equation}\label{quality functional for superposition}
		Q(F(B_1, \cdots, B_p), \tilde{S}) \longrightarrow \underset{p, B_1, \cdots, B_p, F}{\min}
	\end{equation}
	</p>
		
	<h1>Итерационный процесс построения суперпозиции</h1>

	<h2>Описание итерационной процедуры по добавлению операторов</h2>

	<p>Будем последовательно добавлять операторы в суперпозицию.</p>	
	<ul>
		<li> $B_1 = \underset{B}{argmin} Q(B, \tilde{S})$
		<li> $(F, B_1, B_2) = \underset{F, B_1, B_2}{argmin} Q(F(B_1, B_2), \tilde{S})$
		Решать эту задачу слишком сложно, поэтому будем использовать неэквивалентное упрощение. 
		В качестве первого оператора будем использовать оператор полученный на предыдущем шаге. Т.е.
		$(F, B_1, B_2) = \underset{F, B_2}{argmin} Q(F(B_1, B_2), \tilde{S})$
		<li> $(F, B_1, B_2, B_3) = \underset{F, B_3}{argmin} Q(F(B_1, B_2, B_3), \tilde{S})$
		$\cdots$
	</ul>
	<p>Это внешний цикл настройки суперпозиции, который останавливается, 
	когда $|Q_{new} - Q_{old}| < \varepsilon $, где $Q_{new}$ и $Q_{old}$ &mdash; значение функционала, 
	достигнутое после очередной итерации и полученное при предыдущей итерации соответственно.</p>
	
	<h2>Описание итерационной процедуры по настройке пары корректируещего оператора</h2>

	<p>При каждой итерации внешнего цикла надо решать задачу оптимизации 
	$(F, B_1,\cdots, B_p) = \underset{F, B_p}{argmin} Q(F(B_1, \cdots, B_{p-1}, B_p), \tilde{S})$. 
	Для этого входим во внутренний цикл, который будет решать эту задачу методом покоординатного спуска(опять используем неэквивалентное упрощение).</p>	
	<ul>
		<li>$F^0$ &mdash; задаем некоторое начальное приближение для корректирующей операции
		<li>$B_p^i = \underset{B_p}{argmin} Q(F^{i-1}(B_1, \cdots, B_{p-1}, B_p), \tilde{S})$
		<li>$F^i = \underset{F}{argmin} Q(F(B_1, \cdots, B_{p-1}, B_p^i), \tilde{S})$
	</ul>
	
	<p>Проводим итерации цикла 1 - 2 до того, как $|Q'_{new} - Q'_{old}| < \delta $, где $Q'_{new}$ и $Q'_{old}$ &mdash; значение функционала, 
	достигнутое после очередной итерации и полученное при предыдущей итерации соответственно.</p>
	
	<h2>Список "элементарных" действий для настройки (в задании 2 их 6 штук)</h2>

	<p>Для реализации изложенного итерационного подхода необходимо уметь выполнять следующие действия:</p>
	<ul>
	 	<li> $B^* = \underset{B}{argmin}Q(B, \tilde{S})$;
	 	<li> $F^*_p \mapsto F^0_{p+1}$;
	 	<li> $B^* = \underset{B}{argmin}Q(F(B_1, \cdots, B_{p-1}, B), \tilde{S})$;
	 	<li> $F^* = \underset{F}{argmin}Q(F(B_1, \cdots, B_p), \tilde{S})$
	 	<li> критерий останова для внутреннего цикла $|Q'_{new} - Q'_{old}| < \delta $;
	 	<li> критерий останова для цикла наращивания p $|Q_{new} - Q_{old}| < \varepsilon $;
	</ul>	

	<p>Для добавления сразу двух операторов:</p>
	<ul>	
	 	<li> $F^*_p \mapsto F^0_{p+2}$;
	 	<li> $(B^*_{p+1}, B^*_{p+2}) = \underset{B', B''}{argmin}Q(F(B_1, \cdots, B_p, B', B''), \tilde{S})$;
	</ul>

	<p>Для перенастройки ранее добавленного оператора:</p>
	<ul>
	 	<li> $B^*_i = \underset{B}{argmin}Q(F(B_1, \cdots, B_{i-1}, B, B_{i+1}, \cdots, B_p), \tilde{S})$.
	</ul>
	
	<h1>Типы параметров по отношению к оптимизационному подходу</h1>

	<p>Параметры можно разделить на две группы: оптимизируемые и неоптимизируемые.</p>

	<h2>Неоптимизируемые</h2>
	<p>Неоптимизируемые параметры либо фиксируются, либо настраиваются по выборке (с помощью какой-либо эвристики).</p>

	<h2>Оптимизируемые</h2>
	<p>Оптимизируемые параметры могут быть либо найдены аналитиески, либо с помощью численной процедуры оптимизации.</p>



	<h1>Модель оператора 1: Стандартный метод парзеновского окна</h1>
	<h2>Вербальное описание идеи</h2>
	<p>
		Для решения задачи классификации методом парзеновского окна производится Парзеновская оценка плотности, после чего из восстановленных плотностей получают вероятность объекта относиться к каждому из классов.
		В основе метода лежит идея о том, что плотность выше в тех точках, рядом с которыми находится большое количество объектов выборки.
	</p>	
	<h2>Формальное описание </h2>
	<p>
		Запишем Парзеновскую оценку плотности:
		\[ p_{y,h}(x) = \frac{1}{l_y V(h)} \sum_{i=1}^l [y_i = y] K(\frac{\rho(x, x_i)}{h}) \]
		$K(z)$ — произвольная четная функция, называемая функцией ядра или окна. Термин окно происходит из классического вида функции:
		$K(z) = \frac12 [|z| < 1]$
		$p_{y,h}(x)$ - оценка за класс $y$ при ширине окна $h$
	</p>
	<h2>Перечисление параметров оператора</h2>
	<p>
		<table>
			<tr>
				<th>Параметр</th>
				<th>Обозначение</th>
				<th>Область значений</th>
				<th>Тип</th>
			</tr>
			<tr>
				<td>Мера близости объектов</td>
				<td>$\rho$</td>
				<td></td>
				<td>Фиксирован</td>
			</tr>
			<tr>
				<td>Эталоны</td>
				<td>$x_i,y_i$</td>
				<td></td>
				<td>Фиксирован</td>
			</tr>
			<tr>
				<td>Ядро</td>
				<td>$K$</td>
				<td>Четные функции</td>
				<td>Фиксирован</td>
			</tr>
			<tr>
				<td>Ширина окна</td>
				<td>$h$</td>
				<td>$\mathbb{R}_+$</td>
				<td>Фиксирован</td>
			</tr>
			<tr>
				<td>Веса классов</td>
				<td>$l_y$</td>
				<td>$2\mathbb{R}_+$</td>
				<td>Оптимизируемый параметр (численно)</td>
			</tr>
		</table>
	</p>

	<h2>Настройка</h2>
	<p>Предложена "ленивая" реализация, в которой веса всех классов совпадают и равны 1.</p>
	


	<h1>Модель оператора 2: Логарифмические круги</h1>

	<h2>Вербальное описание модели</h2>
	<p>В данной модели используется идея того, что объекты одного класса находятся близко друг к другу, а объекты разных классов находятся далеко друг от друга. Так как появляется понятие близости, то параметром операторов этой модели является метрика. Кроме того, в данной модели предполагается, что в классах можно выбрать эталоны, по отношению к которым и будет измеряться близость или дальность объектов к классу.</p>

	<h2>Формальное описание действия оператора</h2>

	<p>
	\begin{equation}
	\begin{split}
		&B(S_i) = ( \Gamma_1(S_i), \cdots, \Gamma_l(S_i))^T;
		\\
		&\Gamma_j(S_i) = z_j \ln {\frac{\rho(S_i, S_{0_j})}{R_{0_j}}},
	\end{split}
	\end{equation}	
	где
	<ul>
	<li>$ \rho(\cdot, \cdot) $ -- метрика $ \mathfrak{I_i}^2 \rightarrow \mathbb{R}_{+} $.</li>
	<li>$ z_j \in \{ +1, -1\} $ -- метка &laquo;близость-дальность&raquo;. Показывает, что мы считаем: &laquo;насколько близок данный объект к эталону класса&raquo; или &laquo;насколько далек&raquo;.</li>
	<li>$ S_{0_j} $ -- эталон класса.</li>
	<li>$ R_{0_j} $ -- радиус класса.</li>
	</ul>
	</p>

	<p>
	В данной работе были сделаны следующие упрощения:
	<ul>
	<li>$ \rho(\cdot, \cdot) $ -- Евклидова метрика;</li>
	<li>$ R_{0_j} \equiv R_0 - const \textrm{ } \forall j \in \{ \textrm{Класс 1, Класс 2, ..., Класс l} \} $;</li>
	<li>$ z_j \equiv -1 \textrm{ } \forall j \in \{ \textrm{Класс 1, Класс 2, ..., Класс l} \}$.</li>
	</ul>
	</p>
	
	<h2>Параметры оператора</h2>

	<table>
	<tr><td>Название </td><td> Обозначение   </td><td> Область значений  </td><td> Примечание</tr>
	<tr><td>Метрика	</td><td> $\rho$ </td><td> $ \mathfrak{I_i}^2 \rightarrow \mathbb{R}_{+} $ </td><td> Константа</td></tr>
	<tr><td>Метка &laquo;близость-дальность&raquo; </td><td> $ z_j $ </td><td> $ \{ +1, -1 \} $   </td><td> Константа</td></tr>
	<tr><td>Эталон класса </td><td> $ S_{0_j} $ </td><td> $ \mathfrak{I_i} $ </td><td> Оптимизируемый</td></tr>
	<tr><td>Радиус класса </td><td> $ R_{0_j} $ </td><td> $ \mathbb{R}_{+} $ </td><td> Константа</td></tr>
	</table>

	<h2>Настройка модели</h2>

	<p>Как было сказано выше, единственным оптимизируемым параметром является эталон каждого класса $ S_{0_j} $. Поиск оптимального значения параметра $ S_{0_j} $ происходит в результате минимизации функционала (\ref{quality functional for operator}). Выпишем явный вид $ Q $ как функции от $(S_{0_1}, \cdots, S_{0_l})$.
	\begin{equation}
	\begin{split}
		Q(S_{0_1}, \cdots, S_{0_l}, \tilde{S}) &= \frac{1}{q} \sum_{i = 1}^q {\sum_{j = 1}^l {(\Gamma_j(S_i) - c_i(j))^2} } = \\ 
		&=\frac{1}{q} \sum_{i = 1}^q {\sum_{j = 1}^l {(- \ln {\frac{\rho(S_i, S_{0_j})}{R_0}} - c_i(j))^2} } = \\
		&=\frac{1}{q} \sum_{i = 1}^q {\sum_{j = 1}^l {(\ln {\rho(S_i, S_{0_j})} - \ln {R_0} + c_i(j))^2} } \longrightarrow \underset{S_{0_1}, \cdots, S_{0_l}}{\min}, 
	\end{split}
	\end{equation}
	</p>

	<p>Заметим, что каждый эталон $ S_{0_j} $ можно рассматривать отдельно, таким образом, вместо (\ref{quality functional for S}) получаем $ l $ задач оптимизации вида:
	\begin{equation}
		Q(S_{0_j}, \tilde{S}) = \frac{1}{q} \sum_{i = 1}^q {(\ln {\rho(S_i, S_{0_j})} - \ln {R_0} + c_i(j))^2} \longrightarrow \underset{ S_{0_j} }{\min}
	\end{equation}
	</p>

	<p>Полученная оптимизационная задача относится к классу квадратичных задач. Будем искать ее решение с помощью метода Монте-Карло.</p>

	<h1>Корректирующая операция 1: Монотонная линейная КО</h1>

	<h2>Вербальное описание</h2>

	<p>Семейство монотонных линейных КО &mdash; это семейство линейных преобразований над пространством оценок,
	которая для данного набора оценок алгоритмических операторов возвращает значение из пространства оценок. 
	Такая КО представляет собой линейную комбинацию оценок алгоритмических операторов с неотрицательными весами.</p> 

	<h2>Формальное описание</h2>
	<p>Корректирующие операции данного вида выглядят следующим образом:
	$$F(B_1, \dots, B_P) = a_1 B_1 + \dots + a_p B_p, $$
	где $a_1, \dots, a_p \ge 0, B_1, \dots, B_p $ - оценки соответствующих операторов</p>

	<h2>Использование модели</h2>
	<p>КО принимает на вход оценки $p$ алгоритмических операторов: $\vec{\Gamma}^1, \dots, \vec{\Gamma}^p$. Параметрами являются $p$ неотрицательных весов: $a_1, \dots, a_p$. 
	Результатом корректирующей операции является оценка, подсчитываемая по следующей формуле:
	\[
	\vec{\Gamma} = \alpha_1\vec{\Gamma}^1 + \ldots + \alpha_p\vec{\Gamma}^p$, &nbsp; где $\{\alpha_1, \dots, \alpha_p\ \in \mathbb{R}_+\}.
	\]
	</p>

	<p>Результат работы корректирующего оператора полностью опеределен оценками алгоритмических моделей и своими параметрами и принадлежит пространству оценок.</p>


	<h2>Перечисление параметров модели операторов</h2>

	<p>В таблице приведены параметры модели:</p>

	<table>
	<tr>
	<th>Название параметра</th>
	<th>Обозначение параметра</th>
	<th>Область допустимых значений</th>
	<th>Тип параметра</th>
	</tr>
	<tr>
	<td>Арность оператора</td>
	<td>$p$</td>
	<td>$\mathbb{N}$</td>
	<td>Оптимизируемый</td>
	</tr>
	<tr>
	<td>Веса оценок</td>
	<td>$\vec{a}$</td>
	<td>$\mathbb{R}_+^p$</td>
	<td>Оптимизируемый</td>
	</tr>
	</table>


	<h2>Настройка параметров</h2>

	<p>Необходимо настроить арность оператора и вектор весов.</p>

	<p>Арность оператора будем увеличивать на единицу, добавляя по одному распознающему оператору, 
	пока не будет выполнен критерий останова &mdash;  достижение локального минимума функционала качества, 
	то есть последний добавленный оператор не уменьшил функционал.</p>

	<p>При фиксированной арности требуется минимизировать следующий функционал:
	\[
	Q(\vec{\alpha}, S) = \frac{1}{ql} \sum_{i = 1}^{q} \|  \alpha_1\vec{\Gamma}^1 + \ldots + \alpha_p\vec{\Gamma}^p - C^{-1}(y_i) \| ^2.
	\]
	</p>

	<p>Это задача условной непрерывной оптимизации по непрерывным параметрам. Для оптимизации вектора весов применим метод покоординатного спуска с убывающим шагом. 
	Изначально положим все координаты вектора весов равными $0.1$, шаг равен $1$. Далее выбирается координата, увеличение которой на величину шага максимально
	уменьшит функционал качества. Ее значение увеличивается на величину шага. Если же такое увеличение любой из координат не уменьшает функционал, то величина шага
	уменьшается вдвое. Итерации продолжаются, пока величина шага больше $10^{-3}$.</p>


	<h1>Корректирующая операция 2: Комитет большинства</h1>

	<h2>Вербальное описание корректирующей операции</h2>

	<p>Комитет большинства(простое голосование, или голосование закономерностей, - англ. ComBoost) известен как алгоритм кластеризации для двух классов с обобщением для многих.	
	Основная идея заключается в применении нескольких операторов к одному объекту и увеличении оценки за тот класс, за который объект получил большую суммарную оценку от операторов.</p>

	<h2>Формальное описание корректирующей операции</h2>

	<p>Пусть имеется объект $\tilde{S} \in \mathfrak{S}$ и набор операторов $(B_1, \dots, B_p) \in \left(\mathfrak{M}[\pi]\right)^p$. Тогда скорректированная оценка объекта $\tilde{S}$ вычисляется таким образом: $e^{\tilde{S}} = F(B_1(\tilde{S}), \dots, B_p(\tilde{S})) = (e^{\tilde{S}}_1, \dots, e^{\tilde{S}}_l) \in \mathfrak{I}_e$. Причем $e^{\tilde{S}}_i = \mathbb{I}\left[\frac{1}{p}(B_1^i(\tilde{S}) + \dots +~B_p^i(\tilde{S})) > \alpha_i\right], i = 1 \dots l$. Для определения корректирующей операции надо задать набор порогов $\alpha_i$ для каждого класса.</p>

	<p>Заметим, что применением корректирующих операций из данного семейства к модели алгоритмов мы действительно его расширяем(по крайней мере не сужаем), т.к. данное семейство $\left(\mathfrak{M}[\pi]\right)^p \to \mathfrak{I}$ содержит тождественную корректирующую операцию.</p>

	<h2>Перечисление параметров корректирующей операции</h2>
	<table>
		<tr>
			<th>Название</th>
			<th>Обозначение</th>
			<th>Область значений</th>
			<th>Тип</th>
		</tr>
		<tr>
			<td>Число операторов</td>
			<td>$p$</td>
			<td>$\mathbb{Z}_{+}$</td>
			<td>Настраиваемый</td>
		</tr>
		<tr>
			<td>Операторы</td>
			<td>$(B_1, \dots, B_p)$</td>
			<td>$(\mathfrak{M}[\pi])^p$</td>
			<td>Настраиваемый</td>
		</tr>
		<tr>
			<td>Пороги</td>
			<td>$\alpha_i, i=1,\dots,l$</td>
			<td>[-1, 1]</td>
			<td>Оптимизируемый</td>
		</tr>
	</table>

	<p>Пороги $\alpha_i$ лежат на отрезке $[-1, 1]$. Такое ограничение связано с тем, что функция активации принимает значения от $-1$ до $1$.</p>

	<h2>Настройка корректирующей операции</h2>
	<p>Оптимизируемыми параметрами являются коэффициенты $ \alpha_i, i=1,\dots,l$. Зафиксируем остальные параметры. Оптимальные значения $ \alpha_i, i=1,\dots,l$ находятся при минимизации функционала. Выпишем $ Q $ как фукнцию от $ \alpha_k $:
	\begin{equation}
		Q(\alpha_1, \cdots, \alpha_l, \tilde{S}) = \sum_{j = 1}^q {\sum_{i = 1}^l { \mathbb{I}\left[\sum_{k = 1}^p B_i^k (S_j) > \alpha_i\right] - c_j(i) } } \longrightarrow \underset{\alpha_i}{\min}
	\end{equation} 
	Получили сложную задачу оптимизации. Будем искать ее решение методом Монте-Карло.</p>
{% endblock report %}

<!-- vim: set ft=htmldjango si sw=2 : -->
